---
title: "Untitled"
author: "Mubashira Qari, Erick Hadi, Puja Roy, Marco Castro, Zach Rose"
date: "2025-05-04"
output: html_document
---

---
title: "Data621_Final_Project"
author: "Mubashira Qari"
date: "2025-04-26"
output:
  pdf_document: default
  html_document: default
---


### Load Libraries

```{r, warning = FALSE, message = FALSE}
# Load required packages
library(htmltools)
library(caret)
library(pROC)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(corrplot)
library(skimr)
require(DataExplorer)
require(miscTools)
require(MASS)
require(performance)
require(lmtest)
require(mice)
require(glmnet)
require(Metrics) 
library(patchwork)  # for combining ggplots
library(e1071)
library(car)
library(forcats)      # For better factor handling
library(car)
```

###  load the dataset and understand its structure.

```{r, warning = FALSE, message = FALSE}
# echo=FALSE, include=FALSE

remote_work_df <- read_csv("https://raw.githubusercontent.com/uzmabb182/Data_621/refs/heads/main/Final_Project/Impact_of_Remote_Work_on_Mental_Health.csv")


head(remote_work_df)

```

### Checking & Cleaning Data

```{r}
glimpse(remote_work_df)
summary(remote_work_df)
skim(remote_work_df)
```

### Checking for missing values

```{r}

colSums(is.na(remote_work_df))

```
### Convert categorical variables to factors

```{r}

remote_work_df <- remote_work_df %>%
  mutate(across(where(is.character), as.factor))

```

### Checking Datatypes

```{r}
str(remote_work_df)
```
###  Dropping Employee_ID Column and Update df

```{r}
# Drop the Employee_ID column
remote_work_df <- remote_work_df %>% dplyr::select(-Employee_ID)

# Verify that the column is removed
glimpse(remote_work_df)


```

### Descriptive Statistics for Numeric Columns Summary

```{r}
remote_work_df %>%
  dplyr::select(where(is.numeric)) %>%
  summary()
```
### Descriptive Statistics for Categorical Columns Frequency

```{r}

remote_work_df %>%
  dplyr::select(where(is.factor)) %>%
  map(table)

```

### Distribution Plots for Age column

```{r}
ggplot(remote_work_df, aes(x = Age)) +
  geom_histogram(binwidth = 5, fill = "steelblue", color = "white") +
  theme_minimal() +
  labs(title = "Age Distribution", x = "Age", y = "Count")

```
### Distribution Plots for Work Location vs Stress Level

```{r}
ggplot(remote_work_df, aes(x = Work_Location, fill = Stress_Level)) +
  geom_bar(position = "dodge") +
  labs(title = "Stress Level by Work Location", x = "Work Location", y = "Count") +
  theme_minimal()

```
### Distribution Plots for Mental Health Condition by Gender

```{r}
ggplot(remote_work_df, aes(x = Gender, fill = Mental_Health_Condition)) +
  geom_bar(position = "fill") +
  labs(title = "Mental Health Condition Distribution by Gender", y = "Proportion") +
  theme_minimal() +
  coord_flip()

```
### Correlation (Numeric Features)

```{r}
# Correlation matrix
numeric_data <- remote_work_df %>%
  dplyr::select(where(is.numeric))

cor_matrix <- cor(numeric_data, use = "complete.obs")
round(cor_matrix, 2)

# Optional: Use corrplot for better visuals
library(corrplot)
corrplot(cor_matrix, method = "color", tl.cex = 0.8)

```
### Relationships Exploration for Productivity Change vs Mental Health

```{r}
ggplot(remote_work_df, aes(x = Mental_Health_Condition, fill = Productivity_Change)) +
  geom_bar(position = "dodge") +
  labs(title = "Productivity Change by Mental Health Condition") +
  theme_minimal()

```
###  Relationships Exploration for Sleep Quality by Region

```{r}
ggplot(remote_work_df, aes(x = Region, fill = Sleep_Quality)) +
  geom_bar(position = "dodge") +
  labs(title = "Sleep Quality Across Regions") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
### Automated Exploratory Report 

```{r}
# Generate an HTML report
#create_report(remote_work_df, output_file = "eda_remote_work_report.html")

```
### Check for outliers or inconsistent entries


```{r}
# identify typos or categories like "Prefer not to say" that may need special handling
boxplot(remote_work_df$Hours_Worked_Per_Week, main = "Boxplot of Weekly Hours Worked")

# Check unique values in categorical columns
sapply(remote_work_df %>% dplyr::select(where(is.factor)), levels)

```
### Summary of Insights from Data Exploration

### Dataset Structure and Quality

The dataset includes a diverse set of variables like below: 

demographic (age, gender, region)
work-related (job role industry, work location) 
mental health (stress level mental health condition, access to resources)
and lifestyle factors (sleep quality, physical activity)

No missing values were reported — indicating a complete dataset suitable for direct analysis.

All categorical columns were successfully converted to factors, and numeric variables are in usable form.

Employee_ID was removed correctly, avoiding unnecessary noise.

### Interpretation of Charts:

### Age Distribution Chart

25–30, 40–50, and 50–55 age bins have the highest frequencies.

Each of these bins has 650–700 employees, indicating a strong middle-aged workforce presence.

The 18–22 group has the lowest count (under 150).

The 60+ group also has fewer participants (around 400), possibly due to retirements or reduced digital/remote work participation.

This is not a normal (bell-shaped) distribution. Instead, it’s closer to a uniform or flat distribution from ages 25 to 55.

The slight dip at the edges (youngest and oldest) is typical in workplace data where fewer very young or senior employees are present.

### Stress Level by Work Location Chart

Remote workers report the highest number of high stress levels, noticeably more than hybrid or onsite workers.

Onsite workers have the most balanced distribution, with slightly more reporting low stress than high.

Hybrid workers show a fairly even spread across all stress levels, suggesting a moderate stress profile.

### Mental Health Condition Distribution by Gender Chart

Anxiety is the most common condition across all genders, especially among males and females.

Non-binary and “Prefer not to say” groups have higher proportions of depression and burnout compared to the binary genders.

The "None" category (no mental health condition) is least prevalent in the non-binary and "Prefer not to say" groups.

Males have the highest proportion of "None" (no mental health condition).

### Correlation Matrix of Numeric Variables Chart

Strongest Positive Correlation:

Age and Years_of_Experience show a strong positive correlation (~0.9+), which is expected—older individuals typically have more work experience.

Moderate Positive Relationships:

Hours_Worked_Per_Week has a moderate positive correlation with Number_of_Virtual_Meetings, suggesting those who attend more meetings tend to work more hours.

Weak or No Correlations:

Most other relationships (e.g., Company_Support_for_Remote_Work, Work_Life_Balance_Rating, Social_Isolation_Rating) show low or negligible correlations, indicating they may vary independently.

No Evidence of Multicollinearity:

No pairs of variables (besides age/experience) show very high correlation (>0.85), so there's low risk of multicollinearity in predictive modeling.

### Productivity Change by Mental Health Condition Chart

Decrease in Productivity is most prominent among individuals with:

Depression (highest drop)

Burnout and Anxiety (also show high counts of decreased productivity)

Individuals with no mental health condition still report productivity decreases, but less frequently compared to those with depression.

Increase in productivity (green bars) is lowest among those with depression, suggesting a clear negative impact of depression on work output.

### Sleep Quality Across Regions Charts

Africa and Oceania have the highest counts of "Good" sleep quality, suggesting relatively better rest patterns among employees in those regions.

Asia and North America show a slightly higher proportion of "Poor" sleep quality, which may indicate higher stress, longer work hours, or less work-life balance.

Europe and South America present a balanced distribution, with no extreme dominance of any sleep quality level.

### Boxplot of Weekly Hours Worked Chart

Median (black line) is around 40 hours/week, which aligns with a standard full-time workload.

The interquartile range (IQR) spans approximately 30 to 50 hours, showing where most employees fall.

The minimum is around 20 hours, and the maximum is close to 60 hours.

There are no extreme outliers shown, but a few employees are working near the upper threshold, which may indicate potential overwork or burnout risk.

### Experimental Methodology for Data Exploration

### 1. Project Initialization

Objective: Investigate how remote work impacts mental health, stress levels, and productivity.

Dataset: "Impact_of_Remote_Work_on_Mental_Health.csv" from GitHub.

Output Format: HTML and PDF documents for reporting.

### 2. Load Required Libraries

Purpose: Load core R packages needed for data handling (tidyverse), visualization (ggplot2, corrplot), modeling (caret, glmnet), and data quality (skimr, DataExplorer).

Key Libraries:

Data wrangling: dplyr, tidyverse, forcats

Visualization: ggplot2, corrplot, patchwork

EDA and utilities: skimr, DataExplorer, car

### 3. Data Import and Initial Inspection

Task: Load the CSV from a GitHub URL using read_csv().

Initial Checks:

head() for preview

glimpse() and summary() for structure

skim() for a richer overview (missing values, distributions, etc.)

### 4. Data Cleaning and Preprocessing

Check for missing values: Use colSums(is.na()) to identify NA patterns.

Convert character to factors: Ensures categorical variables are in correct format.

Drop unnecessary features: Removed Employee_ID as it's non-predictive.

Validate structure: Use str() and glimpse() again post-cleaning.

### 5. Descriptive Statistics

Numerical features: Use summary() on numeric-only columns to inspect distributions.

Categorical features: Use map(table) on factor columns to understand frequency distributions.

### 6. Data Visualization

Univariate Analysis:

Histogram of Age to see workforce age distribution.

Boxplot for Hours_Worked_Per_Week to detect outliers.

Bivariate/Multivariate Analysis:

Bar Charts:

Work_Location vs Stress_Level

Mental_Health_Condition vs Gender

Mental_Health_Condition vs Productivity_Change

Sleep_Quality by Region

Correlation Matrix:

Computed for numeric variables using cor()

Visualized using corrplot()

### 7. Pattern Recognition and Insights

Interpret findings from visualizations and statistical summaries.

Examples:

Older employees tend to have more experience.

Remote work associates with higher stress levels.

Depression correlates with decreased productivity.

Sleep quality varies significantly by region.

### 8. Data Quality & Consistency Checks

Check for inconsistent categorical values (levels()).

Identify unusual entries like "Prefer not to say".

Visual outlier detection using boxplots.

### 9. Optional: Automated EDA Report

Use DataExplorer::create_report() to generate a full HTML summary (commented out in your code).

10. Outline for Data Preparation (for Modeling Stage)
Missing value handling: Impute or drop depending on feature type.

Encoding:

One-hot for unordered categories.

Ordinal for ordered categories.

Feature Engineering:

Binary flags (e.g., mental health present/absent).

Group rare levels (e.g., job roles or regions).

Scaling:

Normalize Hours_Worked_Per_Week, Social_Isolation_Rating, etc.

Data Balancing:

If class imbalance exists (e.g., Mental_Health_Condition), use SMOTE or reweighting.

Remove Redundant Features: Drop Employee_ID, possibly Region if collinear.

Outlier Treatment: Use boxplots/z-scores to cap or transform.

Target Definition:

Choose Mental_Health_Condition or Productivity_Change as response variables.

Train/Test Split:

Use caret or rsample for stratified sampling.

### Summary: 

This methodology reflects a structured and reproducible approach to exploratory data analysis (EDA) and sets up a solid foundation for machine learning or statistical modeling. It captures:

Data quality assurance

Variable exploration and transformation

Visualization-driven insights

Preparatory steps for predictive modeling



### Possible Data Preparation Steps Outline (Post-Exploration)

#### 1. Handle Missing Values
Check for NA values in both categorical and numerical columns.

Impute or drop:

For numerical features: use median or mean imputation.

For categorical features: use mode or a new category like "Unknown".

There is no NA values in both  categorical and numerical columns.

2. Encode Categorical Variables
Convert categorical features for ML models:

One-hot encoding: for unordered categories (e.g., Job_Role, Industry, Region).

Ordinal encoding: for ordered factors (e.g., Stress_Level, Satisfaction_with_Remote_Work).

3. Feature Engineering
Create new features if beneficial:

Binary flags (e.g., Has_Mental_Health_Issue = if Mental_Health_Condition ≠ "None")

Group rare categories (e.g., combine job roles or industries with low frequency)

Bucket Age or Years_of_Experience into groups if needed

4. Scale / Normalize Numeric Features
Normalize features like:

Hours_Worked_Per_Week

Social_Isolation_Rating

Work_Life_Balance_Rating

Use standardization (z-score) or min-max scaling depending on model choice

5. Balance the Dataset (if needed)
If target variable (e.g., Mental_Health_Condition or Productivity_Change) is imbalanced:

Consider SMOTE, undersampling, or class weighting for classification models

6. Remove Redundant Features
Drop non-informative or leakage-prone features:

Employee_ID (irrelevant for modeling)

Possibly Region or Work_Location if highly correlated with other variables

7. Outlier Detection
Use boxplots or z-scores to detect outliers in:

Hours_Worked_Per_Week, Social_Isolation_Rating, etc.

Decide whether to cap, transform, or remove

8. Ensure Consistent Factor Levels
Standardize labels for categorical values (e.g., "Prefer not to say" may need special handling)

Collapse categories for sparsity or interpretability

9. Create Target Variable (if modeling)
Define the dependent variable:

Classification: Mental_Health_Condition, Productivity_Change

Regression: could be derived scores (e.g., scale of mental health burden)

10. Train-Test Split (if modeling)
Split dataset (e.g., 70% training, 30% testing) using caret or rsample

```{r}
data <- remote_work_df
```

Since this data is simulated there is a lot of data that doesn't make sense. For example, in one of the rows the Age = 27 and Years_of_Experience = 20. This means that this person has been working since age 7, which is unrealistic. So we filtered the data so that Age - Years_of_Experience >= 22.
Keep only rows where (Age - Years_of_Experience) is at least 22.

```{r}
data <- data %>% filter((Age - Years_of_Experience) >= 22)
```


Since, we will be predicting whether people are satisfied with remote work We removed people who voted neutral for Satisfaction_with_Remote_Work
```{r}
data <- data %>% 
  filter(Satisfaction_with_Remote_Work %in% c("Satisfied", "Unsatisfied"))
```

There a handful of categorical variables that need to be converted into factors.
```{r}
data$Gender    <- factor(data$Gender)
data$Job_Role  <- factor(data$Job_Role)
data$Industry  <- factor(data$Industry)
data$Work_Location <- factor(data$Work_Location)
data$Region    <- factor(data$Region)

data$Stress_Level <- factor(data$Stress_Level, levels = c("Low", "Medium", "High"), ordered = TRUE)
data$Work_Life_Balance_Rating <- factor(data$Work_Life_Balance_Rating, ordered = TRUE)
data$Company_Support_for_Remote_Work <- factor(data$Company_Support_for_Remote_Work, ordered = TRUE)

data$Mental_Health_Condition <- factor(data$Mental_Health_Condition)
data$Access_to_Mental_Health_Resources <- factor(data$Access_to_Mental_Health_Resources, 
                                                 levels = c("No", "Yes"))
data$Satisfaction_with_Remote_Work <- factor(data$Satisfaction_with_Remote_Work, 
                                              levels = c("Unsatisfied", "Satisfied"))

```



Creating a binary flag on whether a person has any type of mental health regardless of type. This is to make our data more simple. 
```{r}
data$Has_Mental_Health_Issue <- ifelse(data$Mental_Health_Condition != "None", 1, 0)
data$Has_Mental_Health_Issue <- factor(data$Has_Mental_Health_Issue, 
                                       levels = c(0,1), labels = c("No", "Yes"))
data <- data %>% dplyr::select(-Mental_Health_Condition) 
```

Since we aren't looking into Productivity Change in our research we will drop this column
```{r}
data <- data %>% dplyr::select(-Productivity_Change) 
```

```{r}
glimpse(data)
```
```{r}
model <- glm(Satisfaction_with_Remote_Work ~ Age + Gender + Job_Role + Industry +
             Years_of_Experience + Work_Location + Hours_Worked_Per_Week +
             Number_of_Virtual_Meetings + Work_Life_Balance_Rating +
             Stress_Level + Access_to_Mental_Health_Resources +
             Social_Isolation_Rating + Company_Support_for_Remote_Work +
             Physical_Activity + Sleep_Quality + Region + Has_Mental_Health_Issue,
             data = data, family = binomial)

summary(model)
```
Testing for Multicollinearity 
```{r}
vif_values <- vif(model)
print(vif_values)
```
There seems to be no multicollinearity, which indicates that there is no inter correlations among predictors that are inflating the variances of our parameter estimates



After preparing the data, we split the dataset into an 80/20 split
```{r}
set.seed(621)  
trainIndex <- createDataPartition(data$Satisfaction_with_Remote_Work, 
                                  p = 0.8,  
                                  list = FALSE)

train_data <- data[trainIndex, ]
test_data  <- data[-trainIndex, ]
```


### Modeling & Results

Logistic Regression
```{r}
# Fit logistic regression model
model <- glm(Satisfaction_with_Remote_Work ~ Age + Gender + Job_Role + Industry +
               Years_of_Experience + Work_Location + Hours_Worked_Per_Week +
               Number_of_Virtual_Meetings + Work_Life_Balance_Rating +
               Stress_Level + Access_to_Mental_Health_Resources +
               Social_Isolation_Rating + Company_Support_for_Remote_Work +
               Physical_Activity + Sleep_Quality + Region + Has_Mental_Health_Issue,
             data = train_data, family = binomial)

summary(model)

```

For the assignment, we were interested to understand how remote work affects employee job satisfaction for remote work based on a simulated dataset. Our focus was Satisfaction_with_Remote_Work, and it had two classes: Satisfied and Unsatisfied. Since this is a binary classification problem, our first modeling attempt was logistic regression because it is simple to interpret and can handle binary responses.

Data preparation was conducted before modeling. We removed unrealistic rows where Age - Years_of_Experience < 22, and neutral responders on satisfaction (for a clean contrast between satisfied and dissatisfied groups). Categorical variables were factorized, and a new binary variable Has_Mental_Health_Issue was created from the original Mental_Health_Condition. We also removed non-relevant columns like Productivity_Change and Employee_ID. It was subsequently divided into training and test sets in the ratio of 80/20 to enable proper testing.

To be able to verify stability of our logistic regression model, we checked for multicollinearity using VIF (Variance Inflation Factor), and this confirmed all predictors were not engaged in suspect intercorrelations. We attempted a LASSO-penalized logistic regression attempting variable selection but observed no coefficients were selected — showing absence of strong predictors and suggesting weak signal strength in features.


### LASSO Logistic Regression

```{r}
# Prepare data matrices
x <- model.matrix(Satisfaction_with_Remote_Work ~ . -1, data = train_data)
y <- train_data$Satisfaction_with_Remote_Work

# Encode response as binary for glmnet
y_bin <- ifelse(y == "Satisfied", 1, 0)

# Fit LASSO logistic regression
set.seed(621)
cv.lasso <- cv.glmnet(x, y_bin, alpha = 1, family = "binomial")

# Best lambda
best_lambda <- cv.lasso$lambda.min
best_lambda

# Plot cross-validation curve
plot(cv.lasso)

# Fit model with best lambda
lasso_model <- glmnet(x, y_bin, alpha = 1, family = "binomial", lambda = best_lambda)

# Coefficients
coef(lasso_model)

```

Logistic model output indicated that all but one of the predictor variables were not significant. Some were weakly or marginally significant at 0.10 or 0.05. The following was seen:
Healthcare respondents were significantly more likely to dislike telework (p = 0.039).

Remote workers had moderately increased odds of dissatisfaction compared to onsite workers (p = 0.052), weakly supported Hypothesis 1.

Oceania workers were only sweeter, but the impact was statistically significant (p = 0.0539) only.

Physical activity last week was on the verge of significance (p = 0.07) and indicates that active players would be sweeter, but that needs to be explored.

Model performing measures were low:

Accuracy: 50.7%

Sensitivity ( Identified Unsatisfied): 55.5%

Specificity ( Identified Satisfied): 45.9%

AUC Score: ~0.51 (random-like)

This means that the model can't differentiate between the satisfied and dissatisfied respondents. Poor performance prediction is reflected by the confusion matrix using almost balanced but poor performance — it shows that the data are clean but of poor predictive powers for this specific result.

According to the hypotheses:

Hypothesis 1 is weakly supported: Remote workers were somewhat dissatisfied, although the result is weakly significant.

Hypothesis 2 was not testable since a binary mental health variable had been constructed and the original variable was not present in the model.

Hypothesis 3 was false since Gender did not have a statistically significant effect on stress level or job satisfaction in our logistic model.


### Model Evaluation on Test Set

```{r}
# Predict probabilities on the test set
test_probs <- predict(model, newdata = test_data, type = "response")

# Convert probabilities to predicted classes
test_preds <- ifelse(test_probs > 0.5, "Satisfied", "Unsatisfied")
test_preds <- factor(test_preds, levels = levels(test_data$Satisfaction_with_Remote_Work))

# Confusion Matrix
conf_matrix <- confusionMatrix(test_preds, test_data$Satisfaction_with_Remote_Work)
print(conf_matrix)

# Load required library
library(pROC)

# Convert true labels to numeric: 0 = Unsatisfied, 1 = Satisfied
y_true <- ifelse(test_data$Satisfaction_with_Remote_Work == "Satisfied", 1, 0)

# Compute ROC and AUC
roc_obj <- roc(response = y_true, predictor = test_probs)

# Plot ROC curve
plot(roc_obj, col = "blue", main = "ROC Curve for Logistic Regression")
abline(a = 0, b = 1, lty = 2, col = "gray")

# Print AUC
auc_value <- auc(roc_obj)
cat("AUC:", auc_value, "\n")


```

Summary & Conclusion:


Though logistic regression indicated what variables might be driving remote work satisfaction, predictive strength was weak, and all but a few variables contributed minimally. The model is suggesting industry-wide dissatisfaction but particularly in health care and less latent regional and behavior-based variations (i.e., exercise, where one works). Overall, thus, the judgment is that remote working job satisfaction is a product of highly interactive, multivariate factors which cannot be fully encompassed within the described characteristics.

Subsequent models might then be supplemented with higher-importance data such as open-ended free text responses, personality traits, work environment control, or organizational support systems in addition to the rating scale.

The research did try to predict employee telecommuting job satisfaction with the use of logistic regression application. Despite having clean, well-formatted data, the model was not discriminative and was about 51% accurate and AUC value was at the near chance level. The predictor variables were extremely poor on statistical significance.

There was no evidence to support the existence of the fact that telecommuters were less satisfied (contrary to Hypothesis 1), or working professionals in the health sector were less satisfied. There was little evidence for either Hypothesis 2 (psychological isolation and mental well-being) or Hypothesis 3 (gender difference of the stress level).

Overall, results suggest that job satisfaction among telecommuters is a multifaceted and intricate phenomenon that cannot be accounted for by underlying conditions of work and demographic variables. Future research must take into account the role played by yet more advanced psychological, social, and organizational variables in efforts to maximize predictive validity as well as understanding.


