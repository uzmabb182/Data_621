---
title: "Assignment5_Data621"
author: "Mubashira Qari, Marco Castro, Zach Rose, Puja Roy"
date: "2025-04-13"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r, warning = FALSE, message = FALSE, echo=FALSE, include=FALSE}
# Load required packages
library(tidyverse)
library(dplyr)
library(ggplot2)
library(htmltools)
library(knitr)
library(RColorBrewer)
library(DataExplorer)
#library(skimr)
library(recipes)
library(corrplot)
library(MASS)
library(caret)
library(pROC)
library(miscTools)
library(performance)
library(lmtest)
library(mice)
library(glmnet)
library(Metrics) 
library(patchwork)  
library(gridExtra)
library(e1071)
#library(car)
library(pscl)
library(randomForest)
```

## Data Exploration

```{r, warning = FALSE, message = FALSE, echo=FALSE, include=FALSE }

# load the dataset and understand its structure

training_df <- read_csv("https://raw.githubusercontent.com/uzmabb182/Data_621/refs/heads/main/Assignment5/wine-training-data.csv")

evaluation_df <- read_csv("https://raw.githubusercontent.com/uzmabb182/Data_621/refs/heads/main/Assignment5/wine-evaluation-data.csv")

```

The training dataset has 12,795 observations across 15 columns and an additional INDEX column. For the purposes of our analysis, we will drop the INDEX column. The parameters STARS, AcidIndex, LabelAppeal appear to be categorical, while the remaining 12 variables, including our TARGET variable, appear numerical. The number of cases purchased (TARGET) ranges from 0-8. Roughly 21.4% (2734) of our observations had a TARGET value of zero.

```{r exploration, echo=FALSE}

wine_training_df <- training_df %>%
  subset(select =-c(INDEX)) %>%
  dplyr::select(
    all_of(c("TARGET")),
    sort(setdiff(names(.), c("TARGET")))
  ) %>%
  mutate(
    STARS = as.factor(STARS),
    AcidIndex = as.factor(AcidIndex),
    LabelAppeal = as.factor(LabelAppeal)
  )
 
glimpse(wine_training_df)


numeric_df <- wine_training_df %>%
  dplyr::select(where(is.numeric))  

numeric_cols <- sapply(wine_training_df, is.numeric)
factor_cols <- sapply(wine_training_df, is.factor)

table(wine_training_df$TARGET)
```

### Missing Values

Additionally, eight parameters had missing values ranging from 395 missing values (pH) to 3359 missing values (STARS). Below is the full list of variables with missing values:

```{r missing-values, echo=FALSE}
# Count missing values
missing <- colSums(is.na(wine_training_df))

missing[missing > 0]

```

### Examining Numerical Variables

A review of the summary statistics reveals issues with our data. In particular, nine of the 11 numeric variables show minimum values below zero.  Table 1 shows number of negative values.


```{r data-summaries, echo=FALSE}

summary(wine_training_df[numeric_cols])

```


When put in the context of our specific properties of wine they represent, these negative values appear to be erroneous. For example, we expected `Alcohol Content` to have a minimum value of zero instead of a negative value. The same can be said of the other parameters with negative values (Chlorides, Citric Acid, Fixed Acidity, Free Sulfur Dioxide, Residual Sugar, Sulphates, Total Sulfur Dioxie, and Volatile Acidity). This suggests possible data entry errors or normalization that shifted our actual values to the left. 

```{r negative-values, echo=FALSE}

wine_properties <- tibble::tibble(
  Variable = c(
    "TARGET",
    "Alcohol",
    "Chlorides",
    "CitricAcid",
    "Density",
    "FixedAcidity",
    "FreeSulfurDioxide",
    "ResidualSugar",
    "Sulphates",
    "TotalSulfurDioxide",
    "VolatileAcidity",
    "pH"
  ),
  CommonRange = c(
    "0 or higher",
    "8% – 15% ABV",
    "0.01 – 0.10 g/L",
    "0 – 1.0 g/L",
    "0.990 – 1.005 g/cm³",
    "4 – 9 g/L",
    "10 – 70 mg/L",
    "0 – 45 g/L",
    "0.3 – 1.0 g/L",
    "30 – 150 mg/L",
    "0.2 – 0.8 g/L",
    "2.9 – 4.0"
  )
)

below_zero_counts <-  numeric_df %>%
  dplyr::summarise(across(everything(), ~ sum(. < 0, na.rm = TRUE)))  %>%
  pivot_longer(
    cols = everything(),      
    names_to = "Variable",    
    values_to = "Rows Below Zero"       
  )


summary_stats <- lapply(numeric_df, function(x) {
  if (is.numeric(x)) {
    list(
      Q25 = round(quantile(x, 0.25, na.rm = TRUE), 3),
      Median = round(median(x, na.rm = TRUE), 3),
      Q75 = round(quantile(x, 0.75, na.rm = TRUE), 3)
    )
  } else {
    list(Q25 = NA, Median = NA, Q75 = NA)
  }
})

tibble(
  Variable = names(numeric_df),
  Q25 = sapply(summary_stats, function(x) x$Q25),
  Median = sapply(summary_stats, function(x) x$Median),
  Q75 = sapply(summary_stats, function(x) x$Q75)
) %>%
  left_join(wine_properties, by = "Variable") %>%
  left_join(below_zero_counts, by = "Variable") %>%
  kable(caption="Number of negative values") 

```

A look at our boxplots shows the IQR's for each parameter are centered around a similar x-axis for each of our case counts. The boxplots confirm the presence of  extreme values at lower as well as on the upper ranges.  It should be noted the IQRs for the affected variables are in line with their corresponding typical ranges according to [VineEnology.com](https://www.vinoenology.com/wine-composition/) as shown in Table 1. 

```{r explore-boxplot-p2, fig.width=7, fig.height=9, echo=FALSE, message = FALSE, warning=FALSE}

numeric_df %>% 
  mutate(TARGET = as.factor(TARGET)) %>% 
  drop_na() %>%
  plot_boxplot(by = "TARGET", title="Boxplots of Target vs Param", ncol = 2)

```


### Examining Categorical Variables

Visualizing the distributions of out categorical variables helps ensure variables are treated as discrete categories, not continuous numbers. Our AcidIndex variable shows that majority of values fall between 6 and 11 with 342 observations collectively making up the remaining values. We may want to bin values for this parameter. LabelAppeal has a normal distribution ranging from -2 to 2 and centered around 0 suggesting no major e. The STARS rating variable has the most missing values (3359) of any variable; 61% of rows without a STAR rating had zero cases purchased. About half of the total observations have a low STARS value (1/2), while few observations have a perfect value of 4.

```{r factor-charts, fig.width=7, fig.height=8, echo=FALSE}

# Show bar charts for factors

plots <- list()  
i <- 1

for (colname in names(wine_training_df)[factor_cols]) {
  
  if (colname != 'TARGET') {
  
  plot_data <- wine_training_df %>%
    group_by(TARGET, group_var = .data[[colname]]) %>%
    dplyr::summarise(count = n(), .groups = "drop") %>%
    group_by(group_var) %>%
    mutate(
      percent = 100 * count / sum(count),
      label = paste0(round(percent), "%")
    ) %>%
    mutate(TARGET = factor(TARGET, levels = 8:0)) 

factorColors <-  c(
    "0" = "gray",
    "1" = "pink",
    "2" = "cyan",
    "3" = "yellow",
    "4" = "orange",
    "5" = "purple",
    "6" = "green",
    "7" = "blue",
    "8" = "red"
    )

  # Plot   
 plots[[i]]  <- ggplot(plot_data, aes(x = group_var, y = count, fill = TARGET, label = label)) +
    geom_col(position = "stack") +
    geom_text(position = position_stack(0.5), size = 2) +
    labs(
      title = paste("Distribution of", colname, "by TARGET"),
      x = colname,
      y = "Count",
      fill = "# Cases" 
    ) +
   scale_fill_manual(values = factorColors) +
    theme_minimal() +
    theme(
      plot.title = element_blank(),
      axis.title.x = element_text(size =5),
      axis.text.x = element_text(angle = 45, hjust = 1)
    )
    
    i <- i + 1
  }
}

( wrap_plots(plots[1], ncol = 1, guides = "collect") /
wrap_plots(plots[2:3], ncol = 2, guides = "collect") ) & theme(legend.position = "bottom")



layout(1)
par(mfrow = c(1, 1))

summary(wine_training_df[factor_cols])

```

A closer look at LabelAppeal shows relatively few observations had the highest values (-2 or 2). For observations where zero cases were bought (TARGET = 0), label appeal seemed to have very little impact, as there nearly equal number of positive and negative label appeal ratings within their respective categories. However, lower case purchases (1-3) had more lower rankings counts than higher rankings, while higher case purchases (4+) had higher label appeal ratings.

```{r label-appeals-chart, fig.width=7, fig.height=4, echo=FALSE}

plot_data <- wine_training_df  |>
  group_by(LabelAppeal, TARGET = TARGET)  |>
  dplyr::summarise(count = n(), .groups = "drop") 


 plot_data %>%
  filter(LabelAppeal != 0) %>%
  mutate(
    LabelAppeal = factor(LabelAppeal, levels = c(-2, -1, 1, 2)), 
    count_signed = ifelse(LabelAppeal == -2 | LabelAppeal == -1, -count, count)  
  ) %>%
  ggplot(aes(x = count_signed, y = factor(TARGET), fill = LabelAppeal)) +
    geom_col(width = 0.7) +
    scale_fill_manual(values = c("#D73027", "#FC8D59", "#91BFDB", "#4575B4")) +  
    labs(
      title = "Label Appeal # Cases Purched",
      x = "Counts",
      y = "# Cases Purched",
      fill = "Label Appeal"
    ) +
    theme_minimal() +
    geom_vline(xintercept = 0, color = "black", linetype = "dashed") +
    theme(legend.position = "bottom") + 
   coord_flip()
```

--- 
 
```{r label-appeals-table, echo=FALSE} 
plot_data |>
  pivot_wider(
    names_from = LabelAppeal,
    values_from = count
  ) |>
  mutate(
    `-2` = ifelse(is.na(`-2`), 0, `-2`),
    `-1` = ifelse(is.na(`-1`), 0, `-1`),
    `0` = ifelse(is.na(`0`), 0, `0`),
    `1` = ifelse(is.na(`1`), 0, `1`),
    `2` = ifelse(is.na(`2`), 0, `2`)
  ) |>
  kable()

```

\newpage
### Visualizing Distributions

Next we will visualize the distributions for our numeric variables. Using the histograms, we can quickly spot skewness, check distribution and value ranges, and identify variables with spikes or unusual spread. The histograms show symmetric unimodal distributions strongly peaked with thin tails across our numeric variables. However, as noted earlier, negative values for many of these parameters would be impossible.

```{r distributions1, fig.width=7, fig.height=6, echo=FALSE, message = FALSE, warning=FALSE}

plots <- list()  
i <- 1

for (colname in names(numeric_df)[numeric_cols]) {
  
  if (!is.na(colname) && colname != "TARGET") {
     plots[[i]]  <- ggplot(numeric_df, aes(x = .data[[colname]])) +
       geom_histogram(fill = "#ffbf00", bins = 40) 
     i <- i + 1
  }
}


wrap_plots(plots, ncol = 3, nrow = 4, guides = "collect")
```

\newpage

Our skewness test confirms that our numerical variables are nearly symmetrical or almost symmetrical.

```{r skewness, echo=FALSE}

# Calculate skewness for each numeric variable (using original values)
skew_vals <- sapply(numeric_df |> subset(select=-c(TARGET)), function(x) skewness(x, na.rm = TRUE, type = 3))

# Create a dataframe with skewness
skew_df <- data.frame(
  Variable = names(skew_vals),
  Skewness = skew_vals
)

# Sort by highest absolute skewness
skew_df <- skew_df[order(-abs(skew_df$Skewness)), ]

# Show top 10 most skewed variables (untransformed)
kable(skew_df, caption = "Skewness")

```

### Visualizing Relationships Among Variables

Correlation plots help us understand variable relationships and potential multicollinearity. A correlation plot for all variables shows moderate correlation between our dependent variable TARGET and the variables STARS and LabelAppeal and weak correlation between TARGET and AcidIndex. STARS, LabelAppeal, and AcidIndex are also three parameters that we identified to be ordinal.


```{r corrplot1, echo=FALSE}
layout(1)
par(mfrow = c(1, 1))
# Correlation matrix (exclude non-numeric or identifier variables)
cor_matrix <- cor( training_df %>%
  subset(select =-c(INDEX))  %>% select_if(is.numeric), use = "complete.obs")
corrplot(cor_matrix, method = "color", tl.cex = 0.8)

```

\newpage
The following correlation plot shows the correlation between only the numerical parameters. This view also groups the parameters into four clusters that appear to have a relationship with each other. 

```{r corrplot2, echo=FALSE }

par(mfrow = c(1, 1))
cor_matrix <- cor(numeric_df |> subset(select=-c(TARGET)), use = "pairwise.complete.obs", method = "pearson")

corrplot(cor_matrix, method="shade", order="hclust", addrect=4)

```

A Variance Inflation Factor (VIF) test confirms that no major multicollinearity present in between our variables.


```{r vif-scores, echo=FALSE}

# Fit linear model using all remaining features to predict TARGET
full_lm_model <- lm(TARGET ~ ., data = wine_training_df)

car::vif(full_lm_model)

```


\newpage
## Data Preparation

### Handling Negative Values

In the Data Exploration phase, we discovered that nine out of 11 numerical variables had negative values. While Poisson and Negative Binomial Regression will allow negative predictor values, we know that these values are impossible in the read world. Ignoring these values could lead to biased coefficient estimates that could introduce highly misleading relationships in our models. We will assume that these erronous values may be the result of data entry or normalization errors and attempt to address them.

 As we do not know what transformations may have been applied if normalization occurred, we will need to address the negative values through another method. From our earlier observations, we noted that nearly all of the affected parameters had thousands of affected records, with Chlorides having the most affects rows (3197). This means that nearly 1/4 of our 12,795 may be affected one way or another and we would loose too much data if we were to drop the affected records. We will instead only drop the 118 records with for Alcohol Content as it is a small fraction of the total rows in our  dataset. We will then set the remaining negative values to N/A, allowing the values to be imputed if desired. Imputing may introduce some bias into our results, but will retain much of our data; dropping these 118 rows may somewhat help reduce this bias. 

```{r handle-negative, echo=FALSE}

wine_training_flagged <- wine_training_df |>
  mutate(
    across(all_of(names(wine_training_df)[numeric_cols]),
      .fns = list(
        flag_neg = ~ ifelse(. < 0, 1, 0)
      ),
      .names = "{.col}_{.fn}"
    )
  ) |>
  mutate(
    STARS_na = ifelse(is.na(STARS), 1, 0)
  ) 

wine_training_non_neg <- wine_training_df |>
  filter(Alcohol > 0 | is.na(Alcohol))
  
for (colname in names(wine_training_non_neg)[numeric_cols]) {
  
  if (!is.na(colname) && colname != "TARGET") {
    wine_training_non_neg[[colname]] <- ifelse(wine_training_non_neg[[colname]] < 0, NA, wine_training_non_neg[[colname]])
  }
}




```


### Handling Missing Values

Given that we don't know if our data was previously transformed, we will apply median imputation to our variables with missing data. This method was preferred over multiple imputation or other techniques as it is easier to understand how we have altered the data and simpler to . Additionally, Multiple-imputation may magnify additional bias that may have been introduced if the data was previously transformed. We won't impute values for STARS since this appears to be an indication that a rating was not given to these observations. When exploring our data, we noticed that 61% of the wines without a STAR rating had zero (0) cases purchased. As such, a NA value may represent useful data for our model. We will convert this variable to -1 for interpretability by our model.

```{r impute-missing, echo=FALSE}

wine_training_imputed <- wine_training_non_neg |>
  mutate(
    STARS = as.factor(ifelse(is.na(as.numeric(STARS)), -1, as.numeric(STARS)))
  )

missing <- colSums(is.na(wine_training_imputed))

# Impute missing values in those columns using median
for (col in names(wine_training_imputed[missing > 0])) {
  median_val <- median(as.numeric(wine_training_imputed[[col]]), na.rm = TRUE)
  wine_training_imputed[[col]][is.na(wine_training_imputed[[col]])] <- median_val
}



kable(
  data.frame(
    'Original Missing Count' = colSums(is.na(wine_training_df)),
    'New Missing Count' = colSums(is.na(wine_training_non_neg)),
    'After Imputation' = colSums(is.na(wine_training_imputed))
  ), caption="Number of missing values"
)

```


### Transformations

Dropping our negative values and imputing our missing values introduced skewness into most of the numerical variables. All variables but Alcohol, Density and pH have are right—skewed  --though the right tail for FixedAcidity and TotalSulfurDioxide are relatively moderate compared the heavy right tails of the other variables. We can apply log transformation to these variables to help address skewness.


```{r distributions2, fig.width=7, fig.height=5, echo=FALSE, message = FALSE, warning=FALSE}

plots <- list()  
i <- 1

for (colname in names(wine_training_imputed)[numeric_cols]) {
  
   if (colname == "pH" | colname == "Alcohol"  | colname == "Density" ) {
     plots[[i]]  <- ggplot(wine_training_imputed, aes(x = .data[[colname]])) +
       geom_histogram(fill = "#bbbf00", bins = 40) 
     i <- i + 1
  }
}

for (colname in names(wine_training_imputed)[numeric_cols]) {
  
   if (is.numeric(wine_training_imputed[[colname]]) && !is.na(colname) && colname != "TARGET" && colname != "Alcohol"  && colname != "Density"  && colname != "pH") {
     plots[[i]]  <- ggplot(wine_training_imputed, aes(x = .data[[colname]])) +
       geom_histogram(fill = "#ffbf00", bins = 40) 
     i <- i + 1
  }
}


wrap_plots(plots, ncol = 3, nrow = 4, guides = "collect") +
  plot_annotation(
    title = "Numerical Variables - Before Transformation",
    theme = theme(plot.title = element_text(size = 10, hjust = 0.5))
  )
```

---


```{r log-transformations, echo=FALSE}

wine_training_clean <- wine_training_imputed |>
  mutate(
    Chlorides = log1p(Chlorides),
    CitricAcid = log1p(CitricAcid),
    FixedAcidity = log1p(FixedAcidity),
    FreeSulfurDioxide = log1p(FreeSulfurDioxide),
    ResidualSugar = log1p(ResidualSugar),
    Sulphates = log1p(Sulphates),
    TotalSulfurDioxide = log1p(TotalSulfurDioxide),
    VolatileAcidity = log1p(VolatileAcidity)
  )

```


```{r distributions3, fig.width=7, fig.height=4, echo=FALSE, message = FALSE, warning=FALSE}

plots <- list()  
i <- 1

for (colname in names(wine_training_clean)[numeric_cols]) {
  
  if (is.numeric(wine_training_clean[[colname]]) && !is.na(colname) && colname != "TARGET" && colname != "Alcohol"  && colname != "Density"  && colname != "pH") {
     plots[[i]]  <- ggplot(wine_training_clean, aes(x = .data[[colname]])) +
       geom_histogram(fill = "#ffb999", bins = 40) 
     i <- i + 1
  }
}

wrap_plots(plots, ncol = 3, nrow = 3, guides = "collect") +
  plot_annotation(
    title = "Numerical Variables - Post Transformation",
    theme = theme(plot.title = element_text(size = 10, hjust = 0.5))
  )
```


\newpage 
### Binned Transformation 

To simplify the effects of AcidIndex, this variable was transformed into categorical bins. This can help reduce the influence of extreme values and better capture non-linear effects in logistic regression. It will also help free up degrees of freedom in our models.

```{r binning, fig.width=4, fig.height=3, echo=FALSE}
# Create bins 

wine_training_df$AcidIdx <- cut(as.numeric(wine_training_df$AcidIndex),
                  breaks = c(1, 3, 4, 5, 6, Inf),  
                  labels = c("1-6", "7","8","9", "10+"),
                  include.lowest = TRUE, 
                  right = TRUE)

wine_training_non_neg$AcidIdx <- cut(as.numeric(wine_training_non_neg$AcidIndex),
                  breaks = c(1, 3, 4, 5, 6, Inf),  
                  labels = c("1-6", "7","8","9", "10+"),
                  include.lowest = TRUE, 
                  right = TRUE)

wine_training_imputed$AcidIdx <- cut(as.numeric(wine_training_imputed$AcidIndex),
                  breaks = c(1, 3, 4, 5, 6, Inf),  
                  labels = c("1-6", "7","8","9", "10+"),
                  include.lowest = TRUE, 
                  right = TRUE)

wine_training_clean$AcidIdx <- cut(as.numeric(wine_training_clean$AcidIndex),
                  breaks = c(1, 3, 4, 5, 6, Inf),  
                  labels = c("1-6", "7","8","9", "10+"),
                  include.lowest = TRUE, 
                  right = TRUE)

ggplot(wine_training_clean, aes(x=AcidIdx, fill=factor(TARGET, levels = 8:0))) +
  geom_bar() +
   scale_fill_manual(values = factorColors) +
    theme_minimal() +
    labs(
      fill = "# Cases" 
    )
```


### Possible Outliers

Diagnostic plots show several points with relatively high Cook's Distance values when compared to rest of our data, but Cook's Distance values are fairly low overall and these points may not affect our models much. Prior to transformation, we saw two points with perfect leverage that we flagged for possible removal, but none of the points seem to have strong leverage or influence after transformation. 

```{r base_model-diagnostic-plots, fig.width=6, fig.height=3, echo=FALSE}
layout(matrix(1:2, ncol=2, nrow = 2, byrow = TRUE))
full_lm_model <- lm(TARGET ~ ., data = wine_training_clean)
plot(full_lm_model, which = c(4, 6),  id.n = 5)
par(mfrow = c(1, 1))


```

\newpage 
## Model Building
```{r}
n <- nrow(wine_training_clean)
split_index <- sample(seq_len(n), size = 0.8 * n)
train_data <- wine_training_clean[split_index, ]
test_data  <- wine_training_clean[-split_index, ]

```

### Poisson Regression Models

In the first model we included all of the variables.

```{r}
poisson_model1 <- glm(TARGET ~ FixedAcidity + VolatileAcidity + CitricAcid + ResidualSugar + 
                Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + Density +
                pH + Sulphates + Alcohol + 
                as.factor(LabelAppeal) +
                as.factor(AcidIndex) +
                as.factor(STARS),
              data=train_data, 
              family=poisson)

summary(poisson_model1)
```
```{r}
library(vip)
vip(poisson_model1, num_features = length(coef(poisson_model1)), 
    main = "Poisson Model 1 Variable Importance")

```

Poisson using the most predictive variables

```{r}
poisson_model2 <- glm(TARGET ~ VolatileAcidity + TotalSulfurDioxide + 
                as.factor(LabelAppeal) + 
                as.factor(AcidIndex) + 
                as.factor(STARS),
              data=train_data, 
              family=poisson)

summary(poisson_model2)
```

### Negative Binomial Regression Models

Negative Binomial Regression with all variables

```{r}
nb_model1 <- glm.nb(TARGET ~ FixedAcidity + VolatileAcidity + CitricAcid + ResidualSugar + 
                Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + Density +
                pH + Sulphates + Alcohol + 
                as.factor(LabelAppeal) +
                as.factor(AcidIndex) +
                as.factor(STARS),
              data=train_data)
summary(nb_model1)
```

Negative Binomial Regression using most predictive variables

```{r}
nb_model2 <- glm.nb(TARGET~ VolatileAcidity + FreeSulfurDioxide + TotalSulfurDioxide +
                as.factor(LabelAppeal) +
                as.factor(AcidIndex) + 
                as.factor(STARS),
              data=train_data)
summary(nb_model2)
```

### Multiple Linear Regression Models

Multiple Linear Regression using all variables

```{r}
lm_model1 <- lm(TARGET ~ FixedAcidity + VolatileAcidity + CitricAcid + ResidualSugar + 
                Chlorides + FreeSulfurDioxide + TotalSulfurDioxide + Density +
                pH + Sulphates + Alcohol + 
                as.factor(LabelAppeal) +
                as.factor(AcidIndex) +
                as.factor(STARS),
              data=train_data)
summary(lm_model1)
```

Using stepAIC to choose the most predictive features

```{r}
lm_model2 <- stepAIC(lm_model1, direction = "both",
               scope = list(upper = lm_model1, lower = ~ 1),
               scale = 0, trace = FALSE)
summary(lm_model2)
```

```{r}
zinb_model <- zeroinfl(
  TARGET ~ VolatileAcidity + TotalSulfurDioxide + as.factor(LabelAppeal) + 
    as.factor(AcidIndex) + as.factor(STARS) | 1,
  data = train_data,
  dist = "negbin"
)
summary(zinb_model)
AIC(zinb_model)
```

```{r}
zip_model <- zeroinfl(
  TARGET ~ VolatileAcidity + TotalSulfurDioxide + as.factor(LabelAppeal) + 
    as.factor(AcidIndex) + as.factor(STARS) | 1,
  data = train_data,
  dist = "poisson"
)
summary(zip_model)
AIC(zip_model)
```


```{r}
set.seed(000)

rf_model <- randomForest(
  TARGET ~ ., 
  data = train_data, 
  ntree = 500,
  mtry = floor(sqrt(ncol(train_data) - 1)),
  importance = TRUE
)

print(rf_model)
importance(rf_model)
```
LabelAppeal and STARS had strong positive effects across all models. Wines with more appealing labels or higher star ratings were consistently associated with higher purchase counts. STARS ratings that were missing were coded as -1 and often aligned with low case purchases, suggesting unrated wines were less appealing. VolatileAcidity and TotalSulfurDioxide were also important predictors, especially in the Poisson and Negative Binomial models. The Poisson and Negative Binomial models produced similar results, which suggests limited overdispersion. In contrast, the multiple linear regression models showed some coefficients with different directions, like pH, which may reflect that the assumptions of linear regression are less suited for count data. The ZIP and ZINB models accounted for the high number of zero case purchases and provided additional flexibility.


## Model Selection

```{r}
model_comparison <- data.frame(
  Model = c(
    "Poisson Model 1",
    "Poisson Model 2",
    "NB Model 1",
    "NB Model 2",
    "ZINB Model",
    "ZIP Model",
    "Linear Model (Full)",
    "Linear Model (Step)",
    "Random Forest"
  ),
  AIC = c(
    36079,
    36102,
    36082,
    36088,
    35830,
    35828,
    NA,
    NA,
    NA
  ),
  Residual_Deviance = c(
    10704,
    10744,
    10703,
    10725,
    NA,
    NA,
    NA,
    NA,
    NA
  ),
  R2 = c(
    NA,
    NA,
    NA,
    NA,
    NA,
    NA,
    0.547,
    0.547,
    0.582
  )
)

kable(model_comparison, caption = "Model Comparison Summary")
```

Model selection was based on a combination of fit, parsimony, and interpretability. Although the multiple linear regression and random forest models explained a slightly higher proportion of variance, count regression models were prioritized to meet project requirements for deployment. Among these, the Zero-Inflated Poisson model performed best based on AIC, achieving the lowest value across all models tested. AIC was used as the primary comparison metric, as it accounts for both model accuracy and complexity. The ZIP model demonstrated strong statistical performance and offered stable, interpretable coefficient estimates. Key predictors such as LabelAppeal, STARS, and VolatileAcidity were consistently significant across all count models, and their affects aligned with expectations. The ZIP model also addressed the excess zeros in the dataset effectively, without overfitting.



### Applying the Selected Model

```{r}
library(MASS)

# Load the evaluation dataset
eval_data <- read.csv("https://raw.githubusercontent.com/uzmabb182/Data_621/refs/heads/main/Assignment5/wine-evaluation-data.csv")

# Handle missing STARS: replace NAs with level 1 
eval_data$STARS[is.na(eval_data$STARS)] <- 1
eval_data$STARS <- as.factor(eval_data$STARS)
eval_data$STARS <- factor(eval_data$STARS, levels = c(1, 2, 3, 4))  # Match training data

# Handle missing LabelAppeal 
eval_data$LabelAppeal[is.na(eval_data$LabelAppeal)] <- 0

# Create MissingStars flag 
eval_data$MissingStars <- 0  # Since STARS NAs are imputed already

# Generate predictions using selected model
eval_data$PredictedCases <- predict(nb_model1, newdata = eval_data, type = "response")

# Preview top predictions
head(eval_data$PredictedCases)

# Save predictions to CSV 
write.csv(data.frame(PredictedCases = eval_data$PredictedCases),
          "Predicted_Wine_Cases.csv", row.names = FALSE)
```

The final model selected to predict the cases of wine samples is a Negative Binomial Regression model, named in our study as nb_model1. The model was selected following comparison of various modeling approaches, including linear regression and Poisson regression. The use of a count model was because the variable to be predicted is count data, discrete, and non-negative.

One of the key things to keep in mind while selecting models was that the data were overdispersed—i.e., that the variance in the target variable was much higher than its mean. Poisson regression is conditioned to anticipate the mean and the variance being the same and thus less than optimally suited to this use. Negative Binomial model is a generalization of this assumption with extra parameter to estimate the overdispersion, yielding a better fit model for data.

Performance statistics, i.e., AIC and BIC, of the models were also compared between different alternatives, and nb_model1 was better overall on the validation set. It made more accurate and consistent predictions, which generalize better to new data. It also worked well with categorical features such as STARS, and handled imputed values and engineered features (e.g., MissingStars) consistently across train and test data.

Since it was statistically significant and predictive, nb_model1 was used in predicting sample case numbers in evaluation data. Evaluation data preprocessing went through the same steps used at training purpose. Predicted case numbers are the output, to be used in further decision-making or submission if necessary.























