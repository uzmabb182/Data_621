---
title: "Week1_Data621_HW"
author: "Mubashira Qari"
date: "2025-02-01"
output: html_document
---

### Exercise 1.1:

The dataset teengamb concerns a study of teenage gambling in Britain. Make a
numerical and graphical summary of the data, commenting on any features that
you find interesting. Limit the output you present to a quantity that a busy reader
would find sufficient to get a basic understanding of the data.

### Load the Data

```{r}
library(faraway)
data(teengamb)
```
### Numerical Summary

```{r}
summary(teengamb)
```


```{r}
str(teengamb)  # Structure of the dataset
```
```{r}
sapply(teengamb, function(x) sum(is.na(x)))  # Check for missing values
```

```{r}
cor(teengamb)  # Correlation matrix
```
### Graphical Summary

### Histogram of Gambling Expenditure

```{r}
hist(teengamb$gamble, breaks = 15, col = "lightblue", main = "Distribution of Gambling Expenditure", xlab = "Gambling Amount")
```
### Boxplot to Compare Gambling by Gender

```{r}
boxplot(gamble ~ sex, data = teengamb, col = c("pink", "lightblue"), 
        names = c("Female", "Male"), 
        main = "Gambling Expenditure by Gender", 
        ylab = "Gambling Expenditure")
```
### Scatterplot of Gambling vs. Income

```{r}
plot(teengamb$income, teengamb$gamble, pch = 19, col = "blue",
     xlab = "Income", ylab = "Gambling Expenditure",
     main = "Relationship between Income and Gambling")
abline(lm(gamble ~ income, data = teengamb), col = "red", lwd = 2)

```
### Key Observations:

Gambling Distribution: The histogram may show a skewed distribution, with some teenagers spending significantly more than others.

Gender Differences: The boxplot may reveal that males tend to spend more on gambling than females.

Income Correlation: The scatterplot might suggest a positive relationship between income and gambling expenditure.


### Exercise 1.3:

The dataset prostate is from a study on 97 men with prostate cancer who were
due to receive a radical prostatectomy. Make a numerical and graphical summary
of the data as in the first question.

### Load the Data

```{r}
library(faraway)
data(prostate)
```

### Numerical Summary

```{r}

summary(prostate)  # Summary statistics

```
### Check for Missing Values

```{r}
# Check the structure and missing values:

str(prostate)  # Data types and structure
```


```{r}

sapply(prostate, function(x) sum(is.na(x)))  # Count missing values

```
### Compute Correlation Matrix

```{r}

cor(prostate)  # Correlation matrix

```

This helps identify relationships between different variables in the dataset.

### Visualizing the Data

### Histogram of PSA Levels

```{r}
hist(prostate$lpsa, breaks = 15, col = "lightblue",
     main = "Distribution of Log PSA Levels",
     xlab = "Log PSA Level")
```
### Boxplot of Log Cancer Volume (lcavol)

```{r}
boxplot(prostate$lcavol, col = "lightgreen",
        main = "Boxplot of Log Cancer Volume",
        ylab = "Log Cancer Volume")
```

### Scatter Plot: Log Cancer Volume vs PSA

```{r}
plot(prostate$lcavol, prostate$lpsa, col = "red", pch = 19,
     main = "Log Cancer Volume vs Log PSA",
     xlab = "Log Cancer Volume", ylab = "Log PSA Level")
abline(lm(lpsa ~ lcavol, data = prostate), col = "blue")  # Add regression line
```
### Pairwise Scatter Plot for Key Variables

```{r}
pairs(prostate[, c("lcavol", "lweight", "age", "lbph", "lpsa")], 
      col = "darkgreen", pch = 19)
```
Interpretation of Results:
Summary statistics provide insights into the distribution of PSA levels and other clinical variables.
Histogram shows the distribution of log PSA levels, which are often used instead of raw PSA values.
Boxplot visualizes the distribution of log cancer volume.
Scatter plot examines the relationship between log cancer volume and PSA levels.
Pairwise scatter plots help explore relationships between multiple clinical variables.




### Exercise 1.4:

### Load and Inspect the Data

```{r}
# Load dataset
data(sat)

# View first few rows
head(sat)

# Check structure
str(sat)

# Summary statistics
summary(sat)
```
This provides an overview of the dataset, including variable types and summary statistics like min, max, mean, and quartiles.

### Check for Missing Values

```{r}
colSums(is.na(sat))  # Count missing values per column
```
If missing values exist, handle them using na.omit(sat) or imputation methods.

### Compute Correlation Matrix

```{r}
cor(sat, use = "complete.obs")  # Correlation between numeric variables
```
This helps identify relationships between variables.

### Visualizing the Data

Histogram of SAT Scores

```{r}
hist(sat$total, breaks = 15, col = "lightblue", 
     main = "Distribution of SAT Scores", xlab = "Total SAT Score")
```

### Boxplot of SAT Scores by Expenditure

```{r}
boxplot(sat$total ~ sat$expend, col = "lightgreen",
        main = "SAT Scores vs Expenditure", xlab = "Expenditure", ylab = "Total SAT Score")
```
### Scatter Plot: SAT Scores vs Expenditure

```{r}
plot(sat$expend, sat$total, col = "blue", pch = 19,
     main = "SAT Scores vs School Expenditure", xlab = "Expenditure per Student", ylab = "Total SAT Score")
abline(lm(sat$total ~ sat$expend), col = "red")  # Add regression line
```
Interpretation of Results:

Summary statistics reveal the spread and central tendency of SAT scores and expenditures.
Correlation matrix helps understand relationships between school expenditure and SAT performance.
Histograms & boxplots show the distribution and possible outliers.
Scatter plots help visualize trends, such as whether higher spending leads to better SAT scores

### Exercise 1.5:

### Load and Inspect the Data

```{r}
# Load necessary package
library(faraway)

# Load dataset
data(divusa)

# View first few rows
head(divusa)

# Check structure of dataset
str(divusa)

# Summary statistics
summary(divusa)
```
This provides an overview of the dataset, including variable types and basic statistics like min, max, mean, and quartiles.

### Check for Missing Values

```{r}
colSums(is.na(divusa))  # Count missing values per column
```
If missing values exist, handle them using na.omit(divusa) or imputation techniques

### Compute Correlation Matrix

```{r}
cor(divusa, use = "complete.obs")  # Correlation between numeric variables
```
This helps identify relationships between variables.

### Visualizing the Data

Histogram of Divorce Rate

```{r}
hist(divusa$divorce, breaks = 15, col = "lightblue",
     main = "Distribution of Divorce Rates in the U.S.",
     xlab = "Divorce Rate")
```
### Line Plot of Divorce Rate Over Tim

```{r}

plot(divusa$year, divusa$divorce, type = "l", col = "blue", lwd = 2,
     main = "Divorce Rate in the U.S. (1920-1996)",
     xlab = "Year", ylab = "Divorce Rate")
```
### Scatter Plot: Divorce Rate vs Unemployment

```{r}

plot(divusa$unemployed, divusa$divorce, col = "red", pch = 19,
     main = "Divorce Rate vs Unemployment Rate",
     xlab = "Unemployment Rate", ylab = "Divorce Rate")
abline(lm(divusa$divorce ~ divusa$unemployed), col = "blue")  # Add regression line
```


Interpretation of Results:
Summary statistics provide insights into how the divorce rate varied over time.
Histogram shows the distribution of divorce rates.
Line plot highlights trends in divorce rates from 1920 to 1996.
Scatter plot helps analyze relationships between economic factors (e.g., unemployment) and divorce rates.




Discussion Question:

"In both the teengamb and prostate datasets, we analyzed numerical summaries and visualized relationships between variables. When working with real-world data, what are some potential biases or limitations that might affect the interpretation of these datasets? How can we address these issues to ensure more reliable insights?"

Answer:
When working with real-world datasets like teengamb (teenage gambling behavior) and prostate (prostate cancer patients), there are several potential biases and limitations that could affect our interpretation:

1. Sample Bias
Teengamb Dataset: If the data was collected from a specific region in Britain or from a certain socioeconomic group, the results might not generalize to all teenagers.
Prostate Dataset: The study only includes men who were already scheduled for prostatectomy, meaning it excludes those who opted for other treatments or were undiagnosed. This could introduce selection bias.
2. Measurement Bias
Self-reported gambling behavior (in teengamb) might lead to underreporting or overreporting, affecting the accuracy of the analysis.
PSA levels in prostate could be influenced by factors outside of cancer progression, such as infections or medications, potentially leading to misclassification errors.
3. Confounding Variables
In both datasets, there may be additional unmeasured factors influencing the results.
For teengamb: Parental influence, peer pressure, or cultural factors might impact gambling habits but are not included in the dataset.
For prostate: Lifestyle factors such as diet, exercise, or genetic predisposition could impact PSA levels and tumor growth.
4. Small Sample Size & Outliers
With 97 observations in prostate and a likely small number in teengamb, the findings might not be statistically robust.
Extreme outliers (e.g., exceptionally high gambling expenditure or PSA levels) can skew averages and correlations.
How to Address These Issues?
Improve Data Collection

Use random sampling to ensure a diverse and representative dataset.
Combine self-reported data with objective measures where possible.
Use Statistical Adjustments

Apply techniques like normalization, outlier removal, or transformations (e.g., log transformation of skewed PSA levels).
Conduct regression analysis while controlling for confounders to isolate the effect of key variables.
Validate Findings with External Data

Compare insights from the dataset with other studies to check for consistency.
Use cross-validation techniques to test the robustness of predictive models.
Conclusion
Recognizing and addressing biases in data analysis is crucial to making reliable interpretations. By improving study design, using appropriate statistical techniques, and validating results with external data, we can reduce errors and derive more meaningful insights from datasets like teengamb and prostate.


Answer to other's Question:

Answer:
Regression analysis isn’t about finding a single "true" model—it’s about building a model that’s useful, interpretable, and fits the data well. There are often multiple ways to get to a reasonable and statistically significant answer, so the key is knowing when to choose one model over another and when to stop refining it.
1. Choosing One Model Over Another
A. Model Performance Matters
We typically compare models using metrics like:
•	Adjusted R² – Tells us how well the model explains the data while adjusting for extra variables.
•	AIC/BIC (Akaike/Bayesian Information Criterion) – Helps balance model fit with complexity (lower is better).
•	Cross-validation – Tests how well the model generalizes to new data.
B. Keep It Simple (But Not Too Simple)
•	A model with fewer variables is often better if it explains the data well—this avoids unnecessary complexity.
•	Overfitting is a big risk when we try to make a model too perfect for our dataset; it may not work well with new data.
C. Practicality and Interpretability
•	If two models perform similarly, the simpler one or the one that makes more sense in the real world is usually the better choice.
•	A business or research problem often requires a model that aligns with domain knowledge rather than just statistical fit.
2. When is a Model "Good Enough"?
A model is good enough when it:
•	Answers the research question – Does it provide useful insights?
Follows key assumptions – Is it reasonable and not violating key regression rules (e.g., no multicollinearity, normally distributed errors)?
Generalizes well – Does it work well on new data without being too rigid or too flexible?
Balances accuracy and simplicity – Is it making reliable predictions without overcomplicating things?

•	Instead of chasing a "perfect" model, focus on one that provides meaningful insights, works well for decision-making, and remains stable over different datasets.


