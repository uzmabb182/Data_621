---
title: "Assignment1_Data621"
author: "Mubashira Qari"
date: "2025-02-09"
output: pdf_document
---

### Load Libraries

```{r}

library(tidyverse)
library(readxl)
library(ggplot2)
library(dplyr)
library(stringr)
library(tools)
library(stringdist)
library(broom)
library(gridExtra)
library(gclus)
library(car)
library(VGAM)
library(MASS)
library(rpart.plot)
library(ggfortify)
library(gridExtra)
library(forecast)
library(fpp2)
library(fma)
library(kableExtra)
library(e1071)
library(mlbench)
library(ggcorrplot)
library(DataExplorer)
library(timeDate)
library(caret)
library(GGally)
library(corrplot)
library(RColorBrewer)
library(tibble)
library(tidyr)
library(reshape2)
library(mixtools)
library(skimr)



```

### Data Explorarion:

### Loading Datasets

```{r}

eval_data <- read.csv("https://raw.githubusercontent.com/uzmabb182/Data_621/refs/heads/main/Assignment1/moneyball-evaluation-data%20(1).csv")

train_data <- read.csv("https://raw.githubusercontent.com/uzmabb182/Data_621/refs/heads/main/Assignment1/moneyball-training-data%20(1).csv")

print(eval_data)
print(train_data)
```
### Understanding the TARGET_WINS Field in the Moneyball Dataset:

The TARGET_WINS field represents the number of games a team won in a given baseball season. 

This is the dependent variable (target variable) in the multiple linear regression model.

We are trying to predict TARGET_WINS based on other team performance metrics.

### Viewing Column Names

```{r}
names(eval_data)
names(train_data)

```
### Viewing Field Values:

We can see there are fields with null values

```{r}
glimpse(eval_data)
glimpse(train_data)

```

### Creating Dataframe

```{r}
eval_df <- data.frame(eval_data)
train_df <- data.frame(train_data)
train_df

```



```{r}
str(eval_df)
str(train_df)

```


### Summary of Datasets

```{r}
skim(eval_df)
skim(train_df)
```



```{r}
summary(train_df)
```

```{r}
summary(eval_df)
```



### Calculate mean, median, and standard deviation for key numerical columns

```{r}

train_df %>%
  summarise(across(where(is.numeric), list(mean = mean, median = median, sd = sd), na.rm = TRUE))

``` 
The summarise(across()) function above is calculating the mean, median, ans standard deviation for all the numerical variables.

### Analysis of the training Dataset Before Fitting a Multiple Linear Regression Model:

Before fitting a multiple linear regression (MLR) model, we analyze the dataset for potential issues such as missing values, extreme outliers, multicollinearity, and variable distributions. 

Here's what we can infer from the summary statistics:

### 1. Understanding the Target Variable (TARGET_WINS)

Range: 0 to 146 wins

Mean: ~80.79 wins

Median: 82 wins

Distribution: The min value of 0 and max of 146 suggest some potential outliers or erroneous data points, since most teams win between 50-110 games in a season.

### 2. Missing Values

- Some variables have a significant number of missing values:

TEAM_BATTING_SO (102 missing values)

TEAM_BASERUN_SB (131 missing values)

TEAM_BASERUN_CS (772 missing values) <- potentially unreliable

TEAM_BATTING_HBP (2085 missing values) <- very unreliable

TEAM_PITCHING_SO (102 missing values)

TEAM_FIELDING_DP (286 missing values)

### Actionable Steps:

- Impute missing values (using mean/median or regression techniques).

- Consider removing TEAM_BATTING_HBP and TEAM_BASERUN_CS if they are highly incomplete and do not contribute much.

### 3. Potential Outliers & Data Issues

- Several variables have extreme max values that seem unrealistic:

TEAM_PITCHING_H (Max = 30,132) <- Likely an error since typical values range from 1,200 - 1,700.

TEAM_PITCHING_SO (Max = 19,278) <- Suspiciously high (typical range: 500 - 1,500).

TEAM_PITCHING_BB (Max = 3,645) <- Very high (typical range: 300 - 700).

TEAM_FIELDING_E (Max = 1,898) <- Likely an error since the normal range is ~ 70-200.

### Actionable Steps:

- Check for data entry errors.

- Remove extreme outliers if they distort model performance.

### 4. Feature Selection Considerations:

Batting Variables: TEAM_BATTING_H, TEAM_BATTING_2B, TEAM_BATTING_3B, TEAM_BATTING_HR, TEAM_BATTING_BB are likely strong predictors of team wins.

Pitching Variables: TEAM_PITCHING_H, TEAM_PITCHING_HR, TEAM_PITCHING_BB, TEAM_PITCHING_SO will impact defensive strength.

Fielding Variables: TEAM_FIELDING_E (errors) and TEAM_FIELDING_DP (double plays) may have a weaker impact compared to batting and pitching.

### Multicollinearity Check Needed:

TEAM_PITCHING_H, TEAM_PITCHING_HR, and TEAM_PITCHING_BB may be highly correlated, which can cause multicollinearity in the regression model.

TEAM_BATTING_H, TEAM_BATTING_2B, and TEAM_BATTING_3B may also be strongly correlated since total hits include doubles and triples.

### 5. Data Cleaning Recommendations Before Fitting the Model

Handle Missing Values

Consider dropping or imputing variables with too many missing values (e.g., TEAM_BATTING_HBP).

Impute TEAM_BASERUN_SB, TEAM_BASERUN_CS, and TEAM_FIELDING_DP appropriately.

- Remove or Adjust Extreme Outliers

Remove highly unrealistic values in pitching, fielding, and errors.

- Check for Multicollinearity

Use Variance Inflation Factor (VIF) to detect multicollinearity and drop redundant features.

- Feature Engineering

Consider derived metrics like batting average (H/AB), on-base percentage (OBP), or earned run average (ERA) instead of raw counts.

### Conclusion:

The dataset contains inconsistencies, missing values, and extreme outliers that need to be addressed before fitting an MLR model. 

Once cleaned, feature selection and multicollinearity checks will be essential to ensure a robust and interpretable model for predicting team wins.

### Visualizing Training Dataset:


```{r}

boxplot(train_df$TARGET_WINS, main="Distribution of Team Wins", ylab="Wins", col="lightblue")


```

### Analysis of the Box Plot for TARGET_WINS (Team Wins Distribution)

This box plot provides valuable insights into the distribution of team wins in the training dataset. 

Here’s what we can infer:

### 1. Median and Spread of Wins

The thick horizontal line inside the box represents the median (~82 wins).

The box itself (Interquartile Range - IQR) shows the middle 50% of the data, which seems to range roughly from 70 to 92 wins.

### 1. Box Plot – for Outlier Detection & Distribution Analysis:

- Low-end outliers (~0-40 wins): There are several small circles (outliers) below the lower whisker.

- High-end outliers (~110-146 wins): There are some outliers above the upper whisker, but visually fewer than the low-end.

### Consideration for Regression?

- These low-win teams might be problematic for modeling because they could represent incomplete or missing data.

- Potential data entry issues (e.g., a team with 0 wins) should be checked.

- If extreme values skew the regression, we might need transformations (log scaling)

### 3. Data Skewness and Symmetry

The box is fairly centered, suggesting a roughly symmetric distribution.



```{r}

hist(train_df$TARGET_WINS, 
     main = "Distribution of Team Wins", 
     xlab = "Wins", 
     ylab = "Frequency", 
     col = "steelblue", 
     border = "black", 
     breaks = 20)  # number of bins
```
### Histogram with Density Curve

```{r}

hist(train_df$TARGET_WINS, 
     main = "Histogram of Team Wins with Density Curve", 
     xlab = "Wins", 
     col = "lightgray", 
     border = "black", 
     breaks = 20, 
     probability = TRUE)  # Converts y-axis to density

lines(density(train_df$TARGET_WINS, na.rm = TRUE), 
      col = "red", 
      lwd = 2)  # Adds a red density curve
```
### Data Preparation:

- Analyze Missing Values from Train Datasets.

```{r}
#install.packages("naniar")     # Specialized for missing data visualization
#install.packages("visdat")     # Another missing value visualization package

library(naniar)
library(visdat)
library(dplyr)
library(tidyr)  # tidyr is loaded to use pivot_longer()
```


```{r}

missing_values <- train_df %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Missing_Count")

print(missing_values)

```

```{r}
ggplot(missing_values, aes(y = reorder(Variable, Missing_Count), x = Missing_Count, fill = Missing_Count > 0)) +
  geom_col() +
  labs(title = "Missing Values in Training Dataset",
       x = "Number of Missing Values",
       y = "Variables") +
  scale_fill_manual(values = c("gray", "red"), labels = c("No Missing", "Has Missing")) +
  theme_minimal()
```
### Strategy for Missing Values Column wise:

There are four main options for handling missing values:

### 1. Remove Columns with Too Many Missing Values

If a column has too many missing values (e.g., >50% missing), it may be better to remove it.

The column is mostly empty and not critical.

Example: TEAM_BATTING_HBP (if missing in most rows).

```{r}
# Install if not installed
install.packages("dplyr")  

# Load dplyr
library(dplyr)

train_df <- train_df %>% select(-TEAM_BATTING_HBP)
train_df
```
### 2. Remove Rows with Missing Target (TARGET_WINS)

If the TARGET_WINS column has missing values, remove those rows since we can’t predict missing outcomes.

```{r}

train_df <- train_df %>% filter(!is.na(TARGET_WINS))
train_df
```

### 3. Create a "Missing Indicator" Column

If a column has many missing values, but we want to remove it, we create a new feature that flags missing values:

```{r}
train_df <- train_df %>%
  mutate(TEAM_BASERUN_SB_Missing = ifelse(is.na(TEAM_BASERUN_SB), 1, 0))
#train_df$TEAM_BASERUN_SB_Missing
```

### 4. Verifying That Missing Values Are Fixed

```{r}

sum(is.na(train_df))  # Total missing values
colSums(is.na(train_df))  # Missing values per column

```

